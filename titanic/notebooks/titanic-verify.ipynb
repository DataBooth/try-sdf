{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Verification of basic Titanic-based example in SQLMesh\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    html-math-method: katex\n",
    "    css: styles.css\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: setup\n",
    "#| echo: false\n",
    "\n",
    "import difflib as dl\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itables import init_notebook_mode  # displays dataframes in friendly manner\n",
    "\n",
    "init_notebook_mode(\n",
    "    all_interactive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: data_source\n",
    "#| echo: false\n",
    "\n",
    "DATA_URL = \"https://hbiostat.org/data/repo/titanic3.csv\"  # is this \"definitive\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did a male octogenarian really survive the sinking of the RMS Titanic?\n",
    "\n",
    "### Or: Is there a long-standing error in an oft-used dataset?\n",
    "\n",
    "As it’s not necessarily a word we use often, let me paraphrase: did an 80 year old guy really manage to make it out of the freezing waters to safety following the infamous maritime disaster?\n",
    "\n",
    "The short answer is NO. However, read on and let me explain how this article came to be as part of my Data Science travels – in a [Kaggle](http://www.kaggle.com) warm-up “competition” specifically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source data - \"1999 Original\" (`titanic3`)\n",
    "\n",
    "The source data has moved a few times:\n",
    "\n",
    "- TODO\n",
    "\n",
    "The latest incarnation can be found here:\n",
    "\n",
    "- https://hbiostat.org/data/\n",
    "- https://hbiostat.org/data/repo/titanic\n",
    "- https://hbiostat.org/data/repo/titanic3.csv\n",
    "\n",
    "and has been replicated countless times including the Kaggle version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to find actual date of birth for each passanger? These data sources only have age (it seems)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data sets were downloaded from https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"titanic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_data = f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_csv_auto('{DATA_URL}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_duckdb(sql):\n",
    "    con = duckdb.connect()\n",
    "    con.sql(sql)\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = load_data_duckdb(sql_get_data)\n",
    "duck_df = con.sql(\"SELECT * FROM titanic\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT pclass as passenger_class FROM titanic\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_mesh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.read_csv(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_df.equals(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check local version of file in `seeds` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df = pd.read_csv(\"seeds/titanic3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.rename(columns={\"home_dest\": \"home.dest\"}, inplace=True)  # I needed to change the column name from home.dest to home_dest to get SQLMesh to load data (I believe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.equals(duck_df) # with this rename all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col1 == col2 for col1, col2 in list(zip(seeds_df.columns.tolist(), duck_df.columns.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type1 == type2 for type1, type2 in list(zip(seeds_df.dtypes.tolist(), duck_df.dtypes.tolist()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat([duck_df, seeds_df])\n",
    "differences = concatenated_df.drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(differences) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mesh = duckdb.connect(database=\"titanic_sqlmesh.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mesh.sql(\"PRAGMA show_tables_expanded;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_df = con_mesh.sql(\"SELECT * FROM titanic.raw_data\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_df.rename(columns={\"home_dest\": \"home.dest\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_df.equals(mesh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = con_mesh.sql(f\"SELECT * FROM titanic.final\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "TRAIN_CSV = DATA_DIR / \"train.csv\"\n",
    "TEST_CSV = DATA_DIR / \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(train_df, x='Age', nbins=50)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_extract_names(name):\n",
    "    \"\"\"\n",
    "    Cleans up and extracts components from the 'Name' column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - name (str): The full name string from the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing the title, surname, first name, and other names.\n",
    "    \"\"\"\n",
    "    # Initialize default values for name components\n",
    "    name_parts = {'title': '', 'surname': '', 'first_name': '', 'other_names': ''}\n",
    "    \n",
    "    try:\n",
    "        # Clean name by replacing non-breaking spaces and trimming\n",
    "        clean_name = name.replace(u'\\xa0', ' ').strip()\n",
    "        \n",
    "        # Extract name parts using regular expression\n",
    "        match = re.match(r'(?P<surname>[\\w\\s]+),\\s?(?P<title>[\\w\\s]+)\\.\\s?(?P<rest>[\\w\\s\\(\\)]+)', clean_name)\n",
    "        if match:\n",
    "            name_parts['surname'] = match.group('surname')\n",
    "            name_parts['title'] = match.group('title')\n",
    "            rest = match.group('rest').split()\n",
    "            \n",
    "            # Assuming the first name is always the first word in the remaining string\n",
    "            name_parts['first_name'] = rest[0]\n",
    "            \n",
    "            # The rest of the names are considered as other names\n",
    "            if len(rest) > 1:\n",
    "                name_parts['other_names'] = ' '.join(rest[1:])\n",
    "                \n",
    "            # Special handling for names within parentheses (typically for married women)\n",
    "            paren_name_match = re.search(r'\\(([\\w\\s]+)\\)', clean_name)\n",
    "            if paren_name_match:\n",
    "                # Overwrite first name and clear other names if a parenthetical name is found\n",
    "                name_parts['first_name'] = paren_name_match.group(1).split()[0]\n",
    "                name_parts['other_names'] = ' '.join(paren_name_match.group(1).split()[1:])\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing name: {name}. Error: {e}\")\n",
    "    \n",
    "    return name_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Title', 'Surname', 'Firstname', 'Othernames']] = train_df['Name'].apply(lambda x: pd.Series(clean_and_extract_names(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name'] = train_df['Name'].apply(lambda x : x.replace(u'\\xa0', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(name_string, return_type):\n",
    "    \n",
    "    first_name = 'XXX NO FIRSTNAME XXX'\n",
    "    other_names = ''\n",
    "    \n",
    "    name_str = name_string.split()\n",
    "    if name_str[0][-1] == ',':\n",
    "        surname = name_str[0][0:len(name_str[0])-1]\n",
    "        title = name_str[1][0:len(name_str[1])-1]\n",
    "        my_names = name_str[2:len(name_str)]\n",
    "    else:\n",
    "        surname = name_str[0] + ' ' + name_str[1][0:len(name_str[0])-1]\n",
    "        title = name_str[2][0:len(name_str[2])-1]\n",
    "        my_names = name_str[3:len(name_str)]\n",
    "\n",
    "    first_name = my_names[0]\n",
    "    other_names = ''\n",
    "    for name in my_names[1:len(my_names)-1]:\n",
    "        other_names = other_names + name + ' '\n",
    "    other_names = other_names.rstrip()       \n",
    "        \n",
    "    try:\n",
    "        if my_names[len(my_names)-1][-1] == ')':          # extract female/wife name\n",
    "            other_names = ''\n",
    "            for name in my_names:\n",
    "                other_names = other_names + name + ' '\n",
    "                if name[0] == '(':\n",
    "                    other_names = ''\n",
    "                    first_name = name[1:len(name)]\n",
    "            other_names = other_names.rstrip()\n",
    "            other_names = other_names[0:len(other_names)-1]             \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if return_type == 1:\n",
    "        return title\n",
    "    elif return_type == 2:\n",
    "        return surname\n",
    "    elif return_type == 3:\n",
    "        return first_name\n",
    "    else:\n",
    "        return other_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the Kaggle train and test datasets into one (for comparison to other Titanic data sets/sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(train_df, test_df, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the combined dataset of 1309 (= 891 train + 418 test) passengers, there are 1046 non-null age values.\n",
    "\n",
    "Let's extract the components of the 'Name' field into title, surname, first name and other names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TitleOLd'] = df['Name'].apply(lambda x : extract_names(x, 1))\n",
    "df['SurnameOld'] = df['Name'].apply(lambda x : extract_names(x, 2))\n",
    "df['FirstnameOld'] = df['Name'].apply(lambda x : extract_names(x, 3))\n",
    "df['OthernamesOld'] = df['Name'].apply(lambda x : extract_names(x, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age = df.sort_values(by=['Age', 'Name'])\n",
    "df_sort_age.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the other dataset(s) age data on this plot too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wikipedia = pd.read_html('https://en.m.wikipedia.org/wiki/Passengers_of_the_RMS_Titanic',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_tables = pd.read_html('http://www.titanicfacts.net/titanic-passenger-list.html',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_tables[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_tables[1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_tables[2].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the \"Titanic Facts\" has the data spread across 3 tables with 324 (1st class), 284 (2nd class) and 709 (3rd class) passengers (1317 total) respectively. There is age data for all 1317 passengers. Contrast this with 1309 passengers in the Kaggle dataset [which does not claim to be complete -- in fact, somewhat disappointingly, there does not appear to be a reference for the data] with only 1046 age values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = pd.merge(pd.merge(facts_tables[0], facts_tables[1], how='outer'), facts_tables[2], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.to_csv('facts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also could go heavy-handed with:\n",
    "# pd.to_numeric(df['y'], errors='coerce')\n",
    "\n",
    "def convert_age(age):\n",
    "    try:\n",
    "        return float(age)\n",
    "    except:\n",
    "        try:\n",
    "            return float(age[0:len(age)-1]) / 12.0\n",
    "        except:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts['Age'] = facts['Age'].apply(lambda age : convert_age(age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert age from string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_sort_age = facts.sort_values(by=['Age', 'Surname'])\n",
    "facts_sort_age.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(facts_sort_age['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.plt.plot(facts_sort_age['Age'])\n",
    "#sns.plt.plot(df_sort_age['Age'], 'g')\n",
    "\n",
    "len(df_sort_age['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_sort_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_sort_age.info()\n",
    "print()\n",
    "df_sort_age.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_sort_age['Name'] = facts_sort_age['Surname'] + facts_sort_age['First Names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the operation of the get_close_matches( ) method to see if we can merge the datasets based on the name fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    name_str = dl.get_close_matches(df_sort_age['Name'].iloc[i], facts_sort_age['Name'])\n",
    "    try:\n",
    "        print(str(len(name_str)) + ': ' + name_str[0] + ' / ' + df_sort_age['Name'].iloc[i])\n",
    "    except:\n",
    "        print('No match' + ' / ' + df_sort_age['Name'].iloc[i])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_name(name):\n",
    "    try:\n",
    "        return dl.get_close_matches(name, facts_sort_age['Name'])[0]\n",
    "    except:\n",
    "        return 'No name match'\n",
    "\n",
    "df_sort_age['Name'] = df_sort_age['Name'].apply(lambda name: match_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age[df_sort_age['Name'] != 'No name match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age['KaggleAge'] = df_sort_age['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_sort_age.merge(facts_sort_age, how='left', left_on='Name', right_on='Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['AgeDiff'] = merged['KaggleAge'] - merged['Age_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['AgeDiff'] = merged['AgeDiff'].dropna()\n",
    "merged['AgeDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['AgeDiffMoreEps'] = merged['AgeDiff'].apply(lambda agediff : abs(agediff) > 2)\n",
    "#merged.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['AgeDiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged[merged['AgeDiff'] != 0]\n",
    "fig = px.histogram(merged_df, x='AgeDiff', nbins=75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the most part, allowing for the NaN differences in the data sets they look pretty similar (other than the max age of 80). So let's look at some of the other top values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_sort_age['Age'].sort_values(na_position='first').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age['Age'].sort_values(na_position='first').tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we have a 76 year old -- wonder if this age is also spurious?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort_age.iloc[1044]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes -- another one! Julia Florence Cavendish (who survived) was 25 at the time of the disaster. Her age at death was 76. c.f. https://www.encyclopedia-titanica.org/titanic-survivor/julia-florence-cavendish.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
